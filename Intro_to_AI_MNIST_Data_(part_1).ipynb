{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tejes-Aulakh/Python/blob/main/Intro_to_AI_MNIST_Data_(part_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Data - Using Artificial Neural Networks (ANN)\n",
        "\n",
        "The MNIST dataset is a widely recognized dataset in the field of machine learning and computer vision.\n",
        "\n",
        "### Description:\n",
        "The MNIST dataset consists of 70,000 images of handwritten digits, each represented as a 28x28-pixel grayscale image. This dataset is commonly used for training and testing image classification algorithms, particularly neural networks.\n",
        "\n",
        "### Features:\n",
        "The dataset includes the following features:\n",
        "\n",
        "- **Pixel Values**: Each image is represented by 784 features, corresponding to the 28x28 pixels. Each pixel value ranges from 0 (black) to 255 (white), indicating the intensity of the pixel.\n",
        "\n",
        "These features collectively represent the visual information of the handwritten digits.\n",
        "\n",
        "### Target:\n",
        "The target variable is the digit represented by each image, ranging from 0 to 9. This is a multi-class classification problem where the goal is to correctly identify the digit in each image.\n",
        "\n",
        "### Data Structure:\n",
        "- **Number of samples**: 70,000\n",
        "- **Number of features**: 784 (28x28 pixels)\n",
        "- **Number of classes**: 10 (digits 0 through 9)\n",
        "\n",
        "### Example Data:\n",
        "Here is a sample from the dataset:\n",
        "\n",
        "| Pixel 1 | Pixel 2 | Pixel 3 | ... | Pixel 784 | Digit |\n",
        "|---------|---------|---------|-----|-----------|-------|\n",
        "| 0       | 0       | 0       | ... | 0         | 5     |\n",
        "| 0       | 0       | 0       | ... | 0         | 0     |\n",
        "| 0       | 0       | 0       | ... | 0         | 4     |\n",
        "\n",
        "In this notebook we will apply Artificial Neural Networks (ANN) to classify the handwritten digits in the MNIST dataset. ANNs are powerful models capable of learning complex patterns in data, making them ideal for image recognition tasks. The results demonstrate the effectiveness of ANNs in accurately classifying handwritten digits, showcasing their utility in handling visual data.\n"
      ],
      "metadata": {
        "id": "iGiK8cUaQpbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries\n",
        "\n",
        "You're probably getting quite used to this now; we import all of the usual libraries - plus Keras from TensorFlow.\n",
        "\n",
        "__TensorFlow__ is an open-source machine learning framework developed by Google. It provides a comprehensive ecosystem of tools, libraries, and community resources that enable researchers and developers to build and deploy machine learning applications efficiently. TensorFlow is particularly well-suited for numerical computation and large-scale machine learning tasks.\n",
        "\n",
        "__Keras__ is a high-level neural networks API, written in Python, that runs on top of TensorFlow (as well as other frameworks like Theano and CNTK). It offers a user-friendly, modular, and extensible interface for building and training deep learning models. Keras simplifies the process of designing complex neural networks by providing intuitive functions and pre-built layers, making it accessible for both beginners and experts in machine learning."
      ],
      "metadata": {
        "id": "mmunne-ERZDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "bUTtWPGZRUCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Things Up\n",
        "\n",
        "We just initialise the seed, as we have previously, to ensure reproducability. And then set the maximium number of columns to show to 28 and adjust the width for display purposes later on. The 0.1 will keep 10% for validation."
      ],
      "metadata": {
        "id": "o7g2HEh6Sc0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "pd.set_option(\"display.max_columns\", 28)\n",
        "pd.set_option('display.width', 1000)\n",
        "validation_split = 0.1\n"
      ],
      "metadata": {
        "id": "3ittG5MuSeKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the data\n",
        "Just like the previous models we've looked at have been built into `sklearn`, MNIST is built into `Keras` so we can use a built-in load function. We can then use `train_test_split` built into sklearn to split the data."
      ],
      "metadata": {
        "id": "jR_z5L7CMtoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_val, y_train_val), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=validation_split, stratify=y_train_val, random_state=7)"
      ],
      "metadata": {
        "id": "2VSWhzRzNIxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# See what we've got\n",
        "We can have a look at what that leaves us with."
      ],
      "metadata": {
        "id": "LnjCG6QxN0is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"There are {x_train.shape[0]} samples and {y_train.shape[0]} labels in the training dataset.\")\n",
        "print(f\"Each data sample in the training dataset is an image that is {x_train.shape[1]} pixels by {x_train.shape[2]} pixels.\")\n",
        "print(f\"There are {x_val.shape[0]} samples and labels in the validation dataset.\")\n",
        "print(f\"There are {x_test.shape[0]} samples and labels in the test dataset.\")"
      ],
      "metadata": {
        "id": "YJRWYwR3OETb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# View the data\n",
        "Let's have a look at some of the input images in the training dataset."
      ],
      "metadata": {
        "id": "bSBH7p5qOQYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i_start = 0  # Change this to a different whole number to view different examples.\n",
        "n = 25\n",
        "print(f\"Data samples from {i_start} to {i_start+n-1}:\")\n",
        "plt.subplots(figsize=(10, 10))\n",
        "for j in range(n):\n",
        "    plt.subplot(5, 5, j+1)\n",
        "    plt.imshow(x_train[i_start+j], cmap=plt.get_cmap(\"binary\"))\n",
        "    plt.title(f\"Number {y_train[i_start+j]}\")\n",
        "    plt.xticks(ticks=[])\n",
        "    plt.yticks(ticks=[])"
      ],
      "metadata": {
        "id": "owFOK-i0OWIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might, as a person, find some of these hard to read. So think about the problems the computer may have!\n",
        "\n",
        "#View a single number\n",
        "Let's have a closer look at one of the images.\n",
        "\n",
        "Each image is 28 pixels by 28 pixels, so 28x28 mean there are 784 pixels in each image, each pixel being a feature. We'll also view the raw data as integers."
      ],
      "metadata": {
        "id": "-dBS6KKRO_l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0  # Again you can change this to another whole number to view a different image.\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "plt.imshow(x_train[i], cmap=plt.get_cmap(\"binary\"))\n",
        "plt.title(f\"A handwritten number {y_train[i]}\")\n",
        "minor_ticks = np.linspace(0.5, 27.5, 28)\n",
        "ax.set_xticks(minor_ticks, minor=True)\n",
        "ax.set_yticks(minor_ticks, minor=True)\n",
        "ax.grid(which=\"minor\")\n",
        "plt.xticks(ticks=range(28))\n",
        "plt.yticks(ticks=range(28));\n",
        "print(f\"The raw data of sample {i}. Handwritten number {y_train[i]}:\")\n",
        "df = pd.DataFrame(x_train[i])\n",
        "print(df)"
      ],
      "metadata": {
        "id": "snPbq_-gO_T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you see how the raw data correlates with the printed number?\n",
        "\n",
        "# Prepare the data\n",
        "The data needs to be scaled and reshaped. The scaling makes the numbers 0..1 instead of 0..255 which is easier for the network to deal with, as well as converting the labels into a binary-type representation.\n",
        "\n",
        "The images are then reshaped from _n_ 28x28 squares to _n_ 1x784 strips of data.\n",
        "\n"
      ],
      "metadata": {
        "id": "j9RWZA59RB4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescale the matrices of numbers so that they are 0 to 1 instead of 0 to 255.\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_val = x_val.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Convert each label from a number from 0 to 9 to a 1x10 vector of 0s and 1s\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Reshape\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], 28*28))\n",
        "x_val = np.reshape(x_val, (x_val.shape[0], 28*28))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], 28*28))"
      ],
      "metadata": {
        "id": "x7DVMdlwSAa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see how this changes the data..."
      ],
      "metadata": {
        "id": "Rut8Mm7bTmjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The raw data of sample {i}. Handwritten number {y_train[i]}:\")\n",
        "df = pd.DataFrame(x_train[i])\n",
        "print(df)"
      ],
      "metadata": {
        "id": "NAhD3HoDTeIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constructing the ANN\n",
        "In this section, we will create an artificial neural network (ANN). In the code, the ANN we build will be stored in a variable named `model`."
      ],
      "metadata": {
        "id": "uaPCoSzvUK61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the size of the input layer and the output layer.\n",
        "num_input_nodes = 784  # Each image has 784 pixels (28 x 28): this is the input data size.\n",
        "num_output_nodes = 10  # Ten output nodes for the ten possible outputs: 0, 1, 2, 3,...,9"
      ],
      "metadata": {
        "id": "b-mV2KQhUkYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the size of the hidden layers\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        # Input layer\n",
        "        keras.Input(shape=(num_input_nodes,)),\n",
        "        # Hidden layers\n",
        "        layers.Dense(128, activation='relu', name=\"hidden_layer_1\"),\n",
        "        # Output layer\n",
        "        layers.Dense(num_output_nodes, activation=\"softmax\", name=\"final_layer\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Set the parameters that control the training process\n",
        "batch_size = 128  # Then umber of data samples that are input to the ANN in each training step\n",
        "iterations = 5  # The number of training steps (the number of times that the entire dataset is input to the ANN)"
      ],
      "metadata": {
        "id": "2hEz2slDUmsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarise the model\n",
        "We can call up a summary of the model we have just built."
      ],
      "metadata": {
        "id": "FHbb6ZiKWOAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "4m3ILZwRWSGI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}