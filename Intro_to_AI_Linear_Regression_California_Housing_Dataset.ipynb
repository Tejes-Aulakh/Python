{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tejes-Aulakh/Python/blob/main/Intro_to_AI_Linear_Regression_California_Housing_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# California Housing Data - Using Linear Regression\n",
        "\n",
        "The California Housing dataset is another well-known dataset in the field of machine learning and statistics.\n",
        "\n",
        "## Description:\n",
        "\n",
        "The California Housing dataset consists of 20,640 samples of housing data from California, each described by eight features. This dataset is commonly used to predict housing prices based on various factors.\n",
        "\n",
        "## Features:\n",
        "\n",
        "The dataset includes the following eight features (all continuous):\n",
        "\n",
        "1. MedInc: Median income in block group\n",
        "2. HouseAge: Median house age in block group\n",
        "3. AveRooms: Average number of rooms per household\n",
        "4. AveBedrms: Average number of bedrooms per household\n",
        "5. Population: Block group population\n",
        "6. AveOccup: Average number of household members\n",
        "7. Latitude: Block group latitude\n",
        "8. Longitude: Block group longitude\n",
        "\n",
        "These features represent various demographic and geographic properties of the housing samples.\n",
        "\n",
        "## Target:\n",
        "\n",
        "The target variable is the median house value for California districts, measured in hundreds of thousands of dollars.\n",
        "\n",
        "## Data Structure:\n",
        "\n",
        "* Number of samples: 20,640\n",
        "* Number of features: 8\n",
        "* Number of classes: Not applicable (continuous target variable)\n",
        "\n",
        "## Example Data:\n",
        "\n",
        "Here is a sample from the dataset:\n",
        "\n",
        "| MedInc | HouseAge | AveRooms | AveBedrms | Population | AveOccup | Latitude | Longitude | Median House Value |\n",
        "|--------|----------|----------|-----------|------------|----------|----------|-----------|--------------------|\n",
        "| 8.3252 | 41.0     | 6.9841   | 1.0238    | 322        | 2.5556   | 37.88    | -122.23   | 4.526              |\n",
        "| 8.3014 | 21.0     | 6.2381   | 0.9719    | 2401       | 2.1098   | 37.86    | -122.22   | 3.585              |\n",
        "| 7.2574 | 52.0     | 8.2881   | 1.0811    | 496        | 2.8023   | 37.85    | -122.24   | 3.521              |\n",
        "\n",
        "\n",
        "In this analysis, we applied the Linear Regression algorithm to predict the median house value based on the features provided. Linear Regression is a fundamental regression technique that models the relationship between the input features and a continuous target variable. The results demonstrate the effectiveness of Linear Regression in predicting house prices, showcasing its utility in handling real-world datasets."
      ],
      "metadata": {
        "id": "GN96DRAiqZ0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries\n",
        "\n",
        "Python includes a large number of libraries pre-installed or available through package managers such as pip to support machine learning. The libraries we will be using are NumPy, pandas, and scikit-learn. Like the previous example, we will be plotting the data using matplotlib, with seaborn used on top of it to better suit our needs."
      ],
      "metadata": {
        "id": "bX6G0ntJtdqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "W4s-qkifqZhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset\n",
        "\n",
        "scikit-learn contains the dataset with a one-shot load function `fetch_california_housing()`. It's often a good idea to display the first few lines of a dataset to make sure everything looks as it should."
      ],
      "metadata": {
        "id": "v62JTnrvttTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (example: California Housing dataset)\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "housing = housing.frame"
      ],
      "metadata": {
        "id": "zuDe4NmJqZeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first few rows\n",
        "housing.head()"
      ],
      "metadata": {
        "id": "tlzNU86NLGr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualise the Data\n",
        "\n",
        "WWith so many features, it is often worthwhile to visualise each one as a graph. Note that this is not required for the algorithm to run; it helps us, as humans, to interpret and understand the data.\n",
        "\n",
        "Based on the histograms of the various features, we can observe the following:\n",
        "\n",
        "The features are distributed across very different scales.\n",
        "\n",
        "The `HouseAge` and `HouseValue` columns have capped values at 50 and 5, respectively.\n",
        "\n",
        "To improve accuracy, we should preprocess these features. This can be done by either performing feature engineering or cleaning the problematic instances."
      ],
      "metadata": {
        "id": "aJqadH5OuNKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise the data\n",
        "housing.hist(bins=50, figsize=(12,8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "syDtqzbDqZag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the data\n",
        "\n",
        "We can plot the value of the properties against location using latitude and longitude. You can see this corresponds to a [map of California](https://www.google.com/maps/place/California,+USA/@37.2691675,-119.306607,6z/data=!3m1!4b1!4m6!3m5!1s0x808fb9fe5f285e3d:0x8b5109a227086f55!8m2!3d36.778261!4d-119.4179324!16zL20vMDFuN3E?entry=ttu).\n"
      ],
      "metadata": {
        "id": "CZ9AAdr03Xg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.plot(kind=\"scatter\", x=\"Longitude\",y=\"Latitude\", c=\"MedHouseVal\", cmap=\"jet\", colorbar=True, legend=True, sharex=False, figsize=(10,7), s=housing['Population']/100, label=\"population\", alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UWuUtgDVqY7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The color scale represents house values, and the circle radii indicate population sizes in different areas. From this visualization, we can conclude that:\n",
        "\n",
        "Houses near the ocean have higher values.\n",
        "\n",
        "Houses in densely populated areas also tend to have higher values, although this effect diminishes as we move farther from the ocean.\n",
        "\n",
        "There are some outliers present.\n",
        "\n",
        "## Plot Correlations Between Features\n",
        "Next, we will plot the correlations between the features."
      ],
      "metadata": {
        "id": "holQ6jN8TKRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributes = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup','MedHouseVal']\n",
        "scatter_matrix(housing[attributes], figsize=(12,8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BHZRpptkNyTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By running along the bottom row (`MedHouseVal`) we can compare the correlation of the other features. The strongest one is `MedInc` (median income). This is worth exploring somewhat further.\n",
        "\n",
        "## Explore in more detail."
      ],
      "metadata": {
        "id": "h_cWDofS3pCY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnuKVeaOpj_X"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"MedInc\",y=\"MedHouseVal\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the plot, there seems to be a relatively strong linear correlation between median income and house value.\n",
        "\n",
        "There are some issues, however, such as the lines formed at the top, which result from data capping. This should ideally be addressed during preprocessing.\n",
        "\n",
        "We can view the correlations directly."
      ],
      "metadata": {
        "id": "xWLbAzzX4odq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = housing.corr()\n",
        "corr['MedHouseVal'].sort_values(ascending=True)"
      ],
      "metadata": {
        "id": "9_acJLfMqVsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows the strongest positive correlation is between median house value and median income, as expected.\n",
        "\n",
        "Everything we've done so far is part of understanding the data—doing our due diligence. Now, we need to fit and train the model.\n",
        "\n",
        "## Split for Testing and Training\n",
        "Here, we have randomly split the data, reserving 80% for training and 20% for testing."
      ],
      "metadata": {
        "id": "cXqhJWoVU1OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = housing.iloc[:,:-1]\n",
        "y = housing.iloc[:,-1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "F8CMxsc-VOrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting the Model\n",
        "\n",
        "For better accuracy, standard scaling is applied. The pipeline first applies the `StandardScaler()` function to the features and then calls the Linear Regression model. Using a pipeline makes the code cleaner, more reusable, and reduces boilerplate code significantly.\n"
      ],
      "metadata": {
        "id": "LnjRM2-gVfNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regression_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "regression_pipeline.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "aLw0Zf11VrQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction and Evaluation\n",
        "Now we can try put our test data through the model to get the R<sup>2</sup> value."
      ],
      "metadata": {
        "id": "5Tw_zYgIVxh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regression_pipeline.predict(X_test)\n",
        "r2_score( y_test, y_pred)"
      ],
      "metadata": {
        "id": "VuOVlhYsV0ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives us a value of 0.58. This provides a usable model, but it isn't highly accurate. As evident from the graphs above, there was a positive correlation but numerous issues with the data. The correlation wasn't as strong as it could have been, and many other features also influenced the results. This illustrates how more advanced techniques and methods could be more beneficial."
      ],
      "metadata": {
        "id": "_TlERKFrWWC_"
      }
    }
  ]
}